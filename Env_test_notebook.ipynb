{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabea/anaconda3/envs/rllab_goal_rl/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../rllab-curriculum-master/')\n",
    "import curriculum.envs.arm3d.arm3d_key_env as key_env\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from curriculum.state.utils import StateCollection\n",
    "from curriculum.envs.start_env import generate_starts\n",
    "from rllab.envs.normalized_env import normalize\n",
    "from curriculum.envs.goal_start_env import GoalStartExplorationEnv\n",
    "from curriculum.envs.base import FixedStateGenerator\n",
    "from rllab.misc.instrument import VariantGenerator\n",
    "import random \n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'distance_metric': 'L2', 'goal_size': 9, 'start_size': 7, 'goal_weight': 1, 'ultimate_goal': (0.0, 0.3, -0.7, 0.0, 0.3, -0.4, -0.15, 0.3, -0.55), '_hidden_keys': [], 'start_goal': (1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05), 'extend_dist_rew': False, 'inner_weight': 0, 'terminal_eps': 0.03}]\n"
     ]
    }
   ],
   "source": [
    "vg = VariantGenerator()\n",
    "\n",
    "vg.add('start_size', [7])\n",
    "vg.add('start_goal', lambda start_size: [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05)] if start_size == 7 else\n",
    "           [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05, 0, 0, 0, 0, 0, 0, 0)])\n",
    "vg.add('goal_size', [9])\n",
    "vg.add('ultimate_goal', [(0.0, 0.3, -0.7, 0.0, 0.3, -0.4, -0.15, 0.3, -0.55)])\n",
    "vg.add('terminal_eps', [0.03])\n",
    "vg.add('goal_size', [9])\n",
    "vg.add('distance_metric', ['L2'])\n",
    "vg.add('extend_dist_rew', [False])\n",
    "vg.add('inner_weight', [0])\n",
    "vg.add('goal_weight', lambda inner_weight: [1000] if inner_weight > 0 else [1])\n",
    "\n",
    "print(vg.variants())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = key_env.Arm3dKeyEnv(ctrl_cost_coeff=0)\n",
    "\n",
    "start_state = lambda start_size: [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05)] if start_size == 7 else [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05, 0, 0, 0, 0, 0, 0, 0)]\n",
    "    \n",
    "fixed_start_generator = FixedStateGenerator(state=vg.variants()[0]['start_goal'])\n",
    "fixed_goal_generator = FixedStateGenerator(state=vg.variants()[0]['ultimate_goal'])\n",
    "\n",
    "inner_env = normalize(env)\n",
    "start_goal_env = GoalStartExplorationEnv(\n",
    "        env=inner_env,\n",
    "        start_generator=fixed_start_generator,\n",
    "        obs2start_transform=lambda x: x[:vg.variants()[0]['start_size']],\n",
    "        goal_generator=fixed_goal_generator,\n",
    "        obs2goal_transform=lambda x: x[-1 * vg.variants()[0]['goal_size']:],  # the goal are the last 9 coords\n",
    "        terminal_eps=vg.variants()[0]['terminal_eps'],\n",
    "        distance_metric=vg.variants()[0]['distance_metric'],\n",
    "        extend_dist_rew=vg.variants()[0]['extend_dist_rew'],\n",
    "        inner_weight=vg.variants()[0]['inner_weight'],\n",
    "        goal_weight=vg.variants()[0]['goal_weight'],\n",
    "        terminate_env=True,\n",
    "    )\n",
    "# start_goal_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current obs env: [ 0.1         0.1        -1.54       -1.7         1.54       -0.2         0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.35808759  0.40021986 -0.2249006   0.39271381  0.33405525  0.06565623\n",
      "  0.34470621  0.50946443 -0.04355407]\n",
      "\n",
      "Current obs innver_env: [ 0.1         0.1        -1.54       -1.7         1.54       -0.2         0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.35808759  0.40021986 -0.2249006   0.39271381  0.33405525  0.06565623\n",
      "  0.34470621  0.50946443 -0.04355407]\n",
      "\n",
      "Current obs start_goal_env: [ 0.1         0.1        -1.54       -1.7         1.54       -0.2         0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.35808759  0.40021986 -0.2249006   0.39271381  0.33405525  0.06565623\n",
      "  0.34470621  0.50946443 -0.04355407  0.          0.3        -0.7         0.\n",
      "  0.3        -0.4        -0.15        0.3        -0.55      ]\n"
     ]
    }
   ],
   "source": [
    "print('Current obs env:', env.get_current_obs())\n",
    "print()\n",
    "print('Current obs innver_env:', inner_env.get_current_obs())\n",
    "print()\n",
    "print('Current obs start_goal_env:', start_goal_env.get_current_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step(observation=array([  9.99946865e-02,   9.99798703e-02,  -1.54000041e+00,\n",
      "        -1.69981234e+00,   1.53940944e+00,  -2.00008109e-01,\n",
      "         1.71526437e-03,  -5.31352194e-04,  -2.01297416e-03,\n",
      "        -4.05176616e-05,   1.87657461e-02,  -5.90556392e-02,\n",
      "        -8.10874322e-04,   1.71526437e-01,   3.57898066e-01,\n",
      "         4.00173028e-01,  -2.24882595e-01,   3.92838767e-01,\n",
      "         3.34081640e-01,   6.56532480e-02,   3.44683689e-01,\n",
      "         5.09456491e-01,  -4.35472561e-02]), reward=-12.925766328327672, done=False, info={})\n",
      "[ 0.09999469  0.09997987 -1.54000041 -1.69981234  1.53940944 -0.20000811\n",
      "  0.00171526]\n",
      "Step(observation=array([  9.99838365e-02,   9.99418393e-02,  -1.53999960e+00,\n",
      "        -1.69944313e+00,   1.53824680e+00,  -2.00022649e-01,\n",
      "         5.10890714e-03,  -1.08499979e-03,  -3.80309639e-03,\n",
      "         8.09737420e-05,   3.69211831e-02,  -1.16264835e-01,\n",
      "        -1.45398740e-03,   3.39364277e-01,   3.57520804e-01,\n",
      "         4.00079557e-01,  -2.24846010e-01,   3.93085807e-01,\n",
      "         3.34133592e-01,   6.56471229e-02,   3.44637873e-01,\n",
      "         5.09440231e-01,  -4.35333710e-02]), reward=-12.924762587077481, done=False, info={})\n",
      "[ 0.09998384  0.09994184 -1.5399996  -1.69944313  1.5382468  -0.20002265\n",
      "  0.00510891]\n",
      "Step(observation=array([  9.99673066e-02,   9.98878932e-02,  -1.53999645e+00,\n",
      "        -1.69889822e+00,   1.53653007e+00,  -2.00041641e-01,\n",
      "         1.01449153e-02,  -1.65298416e-03,  -5.39460815e-03,\n",
      "         3.14612621e-04,   5.44913492e-02,  -1.71672860e-01,\n",
      "        -1.89927415e-03,   5.03600814e-01,   3.56957700e-01,\n",
      "         3.99939353e-01,  -2.24789750e-01,   3.93452078e-01,\n",
      "         3.34210400e-01,   6.56372894e-02,   3.44568041e-01,\n",
      "         5.09415219e-01,  -4.35122523e-02]), reward=-12.923247064229342, done=False, info={})\n",
      "[ 0.09996731  0.09988789 -1.53999645 -1.69889822  1.53653007 -0.20004164\n",
      "  0.01014492]\n",
      "Step(observation=array([  9.99450259e-02,   9.98198010e-02,  -1.53999031e+00,\n",
      "        -1.69818322e+00,   1.53427682e+00,  -2.00062810e-01,\n",
      "         1.67881247e-02,  -2.22807592e-03,  -6.80922298e-03,\n",
      "         6.14280674e-04,   7.14992572e-02,  -2.25324537e-01,\n",
      "        -2.11689529e-03,   6.64320938e-01,   3.56210752e-01,\n",
      "         3.99752066e-01,  -2.24712235e-01,   3.93934738e-01,\n",
      "         3.34311484e-01,   6.56227975e-02,   3.44473510e-01,\n",
      "         5.09380989e-01,  -4.34838263e-02]), reward=-12.92121827508292, done=False, info={})\n",
      "[ 0.09994503  0.0998198  -1.53999031 -1.69818322  1.53427682 -0.20006281\n",
      "  0.01678812]\n",
      "Step(observation=array([  9.99169887e-02,   9.97391372e-02,  -1.53998093e+00,\n",
      "        -1.69730357e+00,   1.53150418e+00,  -2.00083584e-01,\n",
      "         2.50041980e-02,  -2.80371299e-03,  -8.06638331e-03,\n",
      "         9.37260696e-04,   8.79657461e-02,  -2.77264184e-01,\n",
      "        -2.07741009e-03,   8.21607337e-01,   3.55282061e-01,\n",
      "         3.99517099e-01,  -2.24611425e-01,   3.94530949e-01,\n",
      "         3.34436382e-01,   6.56023323e-02,   3.44353642e-01,\n",
      "         5.09337042e-01,  -4.34481012e-02]), reward=-12.918678525152249, done=False, info={})\n",
      "[ 0.09991699  0.09973914 -1.53998093 -1.69730357  1.53150418 -0.20008358\n",
      "  0.0250042 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(env.step(action=np.array([0, .0, 0, 0.0, 0.0, 0.0, 1.0])))\n",
    "    print(start_goal_env.start_observation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1       ,  0.1       , -1.54      , -1.7       ,  1.54      ,\n",
       "       -0.2       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.35808759,\n",
       "        0.40021986, -0.2249006 ,  0.39271381,  0.33405525,  0.06565623,\n",
       "        0.34470621,  0.50946443, -0.04355407])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step(observation=array([  1.01547417e-01,   1.03023803e-01,  -1.51973088e+00,\n",
      "        -1.69469985e+00,   1.51925382e+00,  -1.37585055e-01,\n",
      "         3.66337834e-02,   2.89791974e-04,   1.18359424e-02,\n",
      "         5.25020848e-02,  -1.77874524e-02,  -2.39996263e-01,\n",
      "         2.00614523e-01,   1.20744383e-01,   3.57549539e-01,\n",
      "         3.91683973e-01,  -2.29184592e-01,   3.94197313e-01,\n",
      "         3.38675732e-01,   6.38121090e-02,   3.44722133e-01,\n",
      "         5.08833711e-01,  -5.28003624e-02]), reward=-12.767421784493783, done=False, info={})\n"
     ]
    }
   ],
   "source": [
    "with env.set_kill_outside(radius=0.5):\n",
    "    print(env.step(action=np.random.uniform(env.action_space.bounds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09064453,  0.55134477,  0.44003048, -0.48037999, -0.2101182 ,\n",
       "       -0.33983504,  0.51311667])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(*env.action_space.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = '../rllab-curriculum-master/data_upload/state_collections/'\n",
    "old_all_feasible_starts = pickle.load(open(osp.join(load_dir, 'all_feasible_states.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1         0.1        -1.54       -1.7         1.54       -0.2         0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.35808759  0.40021986 -0.2249006   0.39271381  0.33405525  0.06565623\n",
      "  0.34470621  0.50946443 -0.04355407]\n",
      "8\n",
      "-0.224900595763\n",
      "Initialized with start state:\n",
      "[ 1.54941984  0.40005018 -3.72492284 -1.16877705  1.80573215 -2.06306151\n",
      " -0.05838931]\n",
      "\n",
      "[ 1.54952541  0.39858111 -3.74627502 -1.15193943  1.80397772 -2.08335436\n",
      "  0.04660454  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.00637064  0.30922335 -0.68454249 -0.00446433  0.30021146\n",
      " -0.38487369 -0.14893819  0.30308163 -0.54017682]\n"
     ]
    }
   ],
   "source": [
    "# print(env.kill_outside)\n",
    "# print(env.kill_radius)\n",
    "\n",
    "env.reset()\n",
    "obs = env.get_current_obs()\n",
    "print(obs)\n",
    "print((obs == 0).sum())\n",
    "print(obs[16])\n",
    "print('Initialized with start state:')\n",
    "\n",
    "init = old_all_feasible_starts.state_list[1]\n",
    "# init.append(1)\n",
    "print(np.array(init))\n",
    "print()\n",
    "print(env.reset(init_state=old_all_feasible_starts.state_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1       ,  0.1       , -1.54      , -1.7       ,  1.54      ,\n",
       "       -0.2       ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.35808759,\n",
       "        0.40021986, -0.2249006 ,  0.39271381,  0.33405525,  0.06565623,\n",
       "        0.34470621,  0.50946443, -0.04355407])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qpos: [[ 1.54952541]\n",
      " [ 0.39858111]\n",
      " [-3.74627502]\n",
      " [-1.15193943]\n",
      " [ 1.80397772]\n",
      " [-2.08335436]\n",
      " [ 0.04660454]]\n",
      "\n",
      "qvel: [[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "qacc: [[  8.90229372e-13]\n",
      " [ -3.00340019e-12]\n",
      " [ -1.50912239e-12]\n",
      " [ -6.38735709e-12]\n",
      " [  2.33598436e-12]\n",
      " [  1.23119397e-12]\n",
      " [  1.02165410e-13]]\n"
     ]
    }
   ],
   "source": [
    "# in rllab/envs/mujoco/mujoco.py _get_full_obs() get_current_obs is defined\n",
    "print('qpos:', env.model.data.qpos)\n",
    "print()\n",
    "print('qvel:', env.model.data.qvel)\n",
    "print()\n",
    "print('qacc:', env.model.data.qacc)\n",
    "# # print('cinert shape:', env.model.data.cinert.shape)\n",
    "# # print()\n",
    "# # print('cvel:', env.model.data.cvel)\n",
    "# # print()\n",
    "# print('qfrc_actuator:', env.model.data.qfrc_actuator)\n",
    "# print()\n",
    "# # print('cfrc_ext:', env.model.data.cfrc_ext)\n",
    "# # print()\n",
    "# # print('qfrc_constraint:', env.model.data.qfrc_constraint)\n",
    "# # print()\n",
    "# # print('cdists:', env.model.geom_margin)\n",
    "# # print()\n",
    "# print('dcom:', env.dcom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_out_feasible_states_test(env, log_dir=None, distance_threshold=0.1, brownian_variance=1, animate=False):\n",
    "    start_time = time.time()\n",
    "    no_new_states = 0\n",
    "    with env.set_kill_outside():\n",
    "        load_dir = '../rllab-curriculum-master/data_upload/state_collections/'\n",
    "        old_all_feasible_starts = pickle.load(open(osp.join(load_dir, 'all_feasible_states.pkl'), 'rb'))\n",
    "        out_feasible_starts = StateCollection(distance_threshold=distance_threshold)\n",
    "        print('number of feasible starts: ', old_all_feasible_starts.size)\n",
    "        cnt = 0\n",
    "        for start in old_all_feasible_starts.state_list:\n",
    "            obs = env.reset(init_state=start)\n",
    "#             print('Now start %i' %cnt)\n",
    "            cnt += 1\n",
    "            if cnt > 300:\n",
    "                break\n",
    "            if obs[16] > -0.5:\n",
    "                # print(\"got one more up to \", out_feasible_starts.size)\n",
    "                out_feasible_starts.append([start])\n",
    "        print(\"number of out feasible starts:\", out_feasible_starts.size)\n",
    "#         while no_new_states < 5:\n",
    "        total_num_starts = out_feasible_starts.size\n",
    "        starts = out_feasible_starts.sample(100)\n",
    "        new_starts = generate_starts(env, starts=vg.variants()[0]['start_goal'], horizon=10, variance=brownian_variance)# animated=animate, speedup=10, size=10)\n",
    "        out_feasible_starts.append(new_starts)\n",
    "        num_new_starts = out_feasible_starts.size - total_num_starts\n",
    "        logger.log(\"number of new states: \" + str(num_new_starts))\n",
    "        if num_new_starts < 10:\n",
    "            no_new_states += 1\n",
    "#             with open(osp.join(log_dir, 'all_out_feasible_states.pkl'), 'wb') as f:\n",
    "#                 cloudpickle.dump(out_feasible_starts, f, protocol=3)\n",
    "    end_time = time.time()\n",
    "    print('Time needed for start state generation: %.2fmin' %((end_time - start_time)/60))\n",
    "    return out_feasible_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_out_feasible_states(env, log_dir=None, distance_threshold=0.1, brownian_variance=1, animate=False):\n",
    "    start_time = time.time()\n",
    "    no_new_states = 0\n",
    "    with env.set_kill_outside():\n",
    "        load_dir = '../rllab-curriculum-master/data_upload/state_collections/'\n",
    "        old_all_feasible_starts = pickle.load(open(osp.join(load_dir, 'all_feasible_states.pkl'), 'rb'))\n",
    "        out_feasible_starts = StateCollection(distance_threshold=distance_threshold)\n",
    "        print('number of feasible starts: ', old_all_feasible_starts.size)\n",
    "        cnt = 0\n",
    "        for start in old_all_feasible_starts.state_list:\n",
    "            obs = env.reset(init_state=start)\n",
    "#             print('Now start %i' %cnt)\n",
    "            cnt += 1\n",
    "            if cnt > 300:\n",
    "                break\n",
    "            if obs[16] > -0.5:\n",
    "                # print(\"got one more up to \", out_feasible_starts.size)\n",
    "                out_feasible_starts.append([start])\n",
    "        print(\"number of out feasible starts:\", out_feasible_starts.size)\n",
    "        while no_new_states < 5:\n",
    "            total_num_starts = out_feasible_starts.size\n",
    "            starts = out_feasible_starts.sample(100)\n",
    "            new_starts = generate_starts(env, starts=starts, horizon=10, variance=brownian_variance)# animated=animate, speedup=10, size=10)\n",
    "            out_feasible_starts.append(new_starts)\n",
    "            num_new_starts = out_feasible_starts.size - total_num_starts\n",
    "            logger.log(\"number of new states: \" + str(num_new_starts))\n",
    "            if num_new_starts < 10:\n",
    "                no_new_states += 1\n",
    "#             with open(osp.join(log_dir, 'all_out_feasible_states.pkl'), 'wb') as f:\n",
    "#                 cloudpickle.dump(out_feasible_starts, f, protocol=3)\n",
    "    end_time = time.time()\n",
    "    print('Time needed for start state generation: %.2fmin' %((end_time - start_time)/60))\n",
    "    return out_feasible_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feasible starts:  136039\n",
      "2019-01-21 20:00:21.746860 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.747751 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.750673 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.751836 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.756353 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.758002 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.762102 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.763713 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.768525 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.771481 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.775969 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.779127 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.783732 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.787186 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.792430 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.794825 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.798971 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.800774 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.805089 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.809025 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.813847 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.816280 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.819594 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.821145 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.825158 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.826161 CET | after processing, we are left with : (1, 7)\n",
      "2019-01-21 20:00:21.830100 CET | we are trying to append states: (1, 7)\n",
      "2019-01-21 20:00:21.831244 CET | after processing, we are left with : (1, 7)\n",
      "number of out feasible starts: 14\n",
      "the starts from where we generate more is of len:  7\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7acc6242e1f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_out_feasible_states_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_goal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b8b486b6cdd5>\u001b[0m in \u001b[0;36mfind_out_feasible_states_test\u001b[0;34m(env, log_dir, distance_threshold, brownian_variance, animate)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_num_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_feasible_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mstarts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_feasible_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mnew_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_starts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_goal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbrownian_variance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# animated=animate, speedup=10, size=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mout_feasible_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_starts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnum_new_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_feasible_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtotal_num_starts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/start_env.py\u001b[0m in \u001b[0;36mgenerate_starts\u001b[0;34m(env, policy, starts, horizon, size, subsample, variance, zero_action, animated, speedup)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_starts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_observation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_start_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, init_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mGoalExplorationEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mGoalExplorationEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, reset_goal, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#default behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_to_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProxyEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the wrapped env needs to use or ignore it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProxyEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/rllab/envs/proxy_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/rllab/envs/normalized_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_obs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_normalize_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/rllab/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, init_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_mujoco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_com\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom_subtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/rllab/envs/mujoco/mujoco_env.py\u001b[0m in \u001b[0;36mreset_mujoco\u001b[0;34m(self, init_state)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mdatum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mdatum_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mdatum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatum_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mdatum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatum_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "new_starts = find_out_feasible_states_test(start_goal_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[[1,2],[3,4],[5,6]],[[7,8],[9,10],[11,12]]])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 8],\n",
       "       [1, 9],\n",
       "       [1, 7],\n",
       "       [1, 4],\n",
       "       [2, 3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_n(array, n):\n",
    "    ''' sample n elements from the array '''\n",
    "    num_elements = array.shape[0]\n",
    "    inds = np.random.choice(num_elements, size=n, replace=False)\n",
    "    return array[inds,...]\n",
    "\n",
    "sample_n(np.array([[2, 3], [1, 5],[1, 6],[1, 4],[1, 7],[1, 8],[1, 9]]), n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: [ -1.87090204e-04   1.78104648e-03   5.63863710e-03  -3.25645500e-03\n",
      "  -2.06233387e-02  -5.03972428e-03   1.76960641e-02  -9.13712273e-03\n",
      "   2.58631768e-02   1.17504747e-01  -7.32714031e-02  -5.50233942e-01\n",
      "  -2.04712110e-02   5.42521905e-01   1.00262388e+00  -1.87505331e-01\n",
      "  -2.49060001e-01   1.00066944e+00  -1.88318393e-01   5.09325309e-02\n",
      "   1.15164348e+00  -1.87931352e-01  -9.80865646e-02   0.00000000e+00\n",
      "   3.00000000e-01  -7.00000000e-01   0.00000000e+00   3.00000000e-01\n",
      "  -4.00000000e-01  -1.50000000e-01   3.00000000e-01  -5.50000000e-01]\n",
      "reward: 0.0\n",
      "done: False\n",
      "obs_info: {'distance': 2.2418688175841259, 'reward_dist': 0.0, 'goal': (0.0, 0.3, -0.7, 0.0, 0.3, -0.4, -0.15, 0.3, -0.55), 'reward_inner': -0.0, 'goal_reached': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00018709,  0.00178105,  0.00563864, -0.00325645, -0.02062334,\n",
       "       -0.00503972,  0.01769606])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_a = np.random.normal(size=start_goal_env.action_dim)\n",
    "state, reward, done, obs_info = start_goal_env.step(rand_a)\n",
    "print('State:', state)\n",
    "print('reward:', reward)\n",
    "print('done:', done)\n",
    "print('obs_info:', obs_info)\n",
    "start_goal_env.start_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_n(array, n):\n",
    "    ''' sample n elements from the array '''\n",
    "    num_elements = array.shape[0]\n",
    "    inds = np.random.choice(num_elements, size=n, replace=False)\n",
    "    return array[inds, ...]\n",
    "\n",
    "\n",
    "def sample_nearby(env, states, n_new=200, variance=0.9, t_b=50, M=1000):\n",
    "    '''\n",
    "        n_new: number of sampled starts in the ned\n",
    "        t_b:   horizon of one trajectory\n",
    "        M:     number of state list after adding starts\n",
    "\n",
    "    '''\n",
    "    # possibly add: radius which tests if sampled states are in a given\n",
    "    # radius around the sampled start state or around the goal?\n",
    "\n",
    "    starts = np.array(states)\n",
    "    while(len(starts) < M):\n",
    "        # number of starts given by first dimension of starts\n",
    "        # num_starts = starts.shape[0]\n",
    "        # s_0 = starts[np.random.choice(num_starts),...]\n",
    "        s_0 = random.choice(starts)\n",
    "        env.reset(init=s_0)\n",
    "        for i in range(t_b):\n",
    "            a = np.random.normal(scale=variance, size=env.action_dim)\n",
    "            # only want the current observation\n",
    "            _obs, _rew, _done, _env_info = env.step(a)\n",
    "            # only want the start state part of the current state\n",
    "            s_1 = env.start_observation.reshape(1,-1)\n",
    "            starts = np.append(starts, s_1, axis=0)\n",
    "            # rllab also tested if the exploration led through the goal state\n",
    "            # do not see why this is necessary atm\n",
    "\n",
    "    # now sample from the M start states\n",
    "    new_starts = sample_n(starts, n_new)\n",
    "    return new_starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_starts = sample_nearby(start_goal_env, states=[start_goal_env.start_observation])\n",
    "new_starts.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
