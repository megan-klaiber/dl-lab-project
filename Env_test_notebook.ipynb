{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabea/anaconda3/envs/rllab_goal_rl/lib/python3.5/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../rllab-curriculum-master/')\n",
    "import curriculum.envs.arm3d.arm3d_key_env as key_env\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from curriculum.state.utils import StateCollection\n",
    "from curriculum.envs.start_env import generate_starts\n",
    "from rllab.envs.normalized_env import normalize\n",
    "from curriculum.envs.goal_start_env import GoalStartExplorationEnv\n",
    "from curriculum.envs.base import FixedStateGenerator\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = key_env.Arm3dKeyEnv(ctrl_cost_coeff=[0])\n",
    "\n",
    "start_state = lambda start_size: [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05)] if start_size == 7 else [(1.55, 0.4, -3.75, -1.15, 1.81, -2.09, 0.05, 0, 0, 0, 0, 0, 0, 0)]\n",
    "    \n",
    "fixed_start_generator = FixedStateGenerator(state=start_state(7))\n",
    "fixed_goal_generator = FixedStateGenerator(state=[(0.0, 0.3, -0.7, 0.0, 0.3, -0.4, -0.15, 0.3, -0.55)])\n",
    "\n",
    "inner_env = normalize(env)\n",
    "start_goal_env = GoalStartExplorationEnv(env=inner_env, \n",
    "                                         start_generator=fixed_start_generator,\n",
    "                                         obs2start_transform=lambda x: x[:7],\n",
    "                                         goal_generator=fixed_goal_generator,\n",
    "                                         obs2goal_transform=lambda x: x[-9:],\n",
    "                                         terminal_eps=[0.03],\n",
    "                                         distance_metric=['L2'],\n",
    "                                         extend_dist_rew=[False],\n",
    "                                         inner_weight=[0],\n",
    "                                         goal_weight=lambda inner_weight: [1000] if inner_weight > 0 else [1],\n",
    "                                         terminate_env=True\n",
    "                                        )\n",
    "# start_goal_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current obs env: [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     1.001 -0.188 -0.25   1.001 -0.188  0.05   1.151\n",
      " -0.188 -0.1  ]\n",
      "\n",
      "Current obs innver_env: [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     1.001 -0.188 -0.25   1.001 -0.188  0.05   1.151\n",
      " -0.188 -0.1  ]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e4a4370d45b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current obs innver_env:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current obs start_goal_env:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_goal_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_start_env.py\u001b[0m in \u001b[0;36mget_current_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mgoal_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoalExplorationEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStartEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_start_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_env.py\u001b[0m in \u001b[0;36mget_current_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_to_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_env.py\u001b[0m in \u001b[0;36mappend_goal_observation\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_to_goal_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             )\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "print('Current obs env:', env.get_current_obs())\n",
    "print()\n",
    "print('Current obs innver_env:', inner_env.get_current_obs())\n",
    "print()\n",
    "print('Current obs start_goal_env:', start_goal_env.get_current_obs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = 'data_upload/state_collections/'\n",
    "old_all_feasible_starts = pickle.load(open(osp.join(load_dir, 'all_feasible_states.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(env.kill_outside)\n",
    "# print(env.kill_radius)\n",
    "\n",
    "env.reset()\n",
    "obs = env.get_current_obs()\n",
    "print(obs)\n",
    "print((obs == 0).sum())\n",
    "print(obs[16])\n",
    "print('Initialized with start state:')\n",
    "\n",
    "init = old_all_feasible_starts.state_list[1]\n",
    "# init.append(1)\n",
    "print(np.array(init))\n",
    "print()\n",
    "print(env.reset(init_state=old_all_feasible_starts.state_list[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# in rllab/envs/mujoco/mujoco.py _get_full_obs() get_current_obs is defined\n",
    "print('qpos:', env.model.data.qpos)\n",
    "print()\n",
    "print('qvel:', env.model.data.qvel)\n",
    "print()\n",
    "print('qacc:', env.model.data.qacc)\n",
    "# # print('cinert shape:', env.model.data.cinert.shape)\n",
    "# # print()\n",
    "# # print('cvel:', env.model.data.cvel)\n",
    "# # print()\n",
    "# print('qfrc_actuator:', env.model.data.qfrc_actuator)\n",
    "# print()\n",
    "# # print('cfrc_ext:', env.model.data.cfrc_ext)\n",
    "# # print()\n",
    "# # print('qfrc_constraint:', env.model.data.qfrc_constraint)\n",
    "# # print()\n",
    "# # print('cdists:', env.model.geom_margin)\n",
    "# # print()\n",
    "# print('dcom:', env.dcom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(old_all_feasible_starts.state_list[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_out_feasible_states(env, log_dir=None, distance_threshold=0.1, brownian_variance=1, animate=False):\n",
    "    start_time = time.time()\n",
    "    no_new_states = 0\n",
    "    with env.set_kill_outside():\n",
    "        load_dir = 'data_upload/state_collections/'\n",
    "        old_all_feasible_starts = pickle.load(open(osp.join(load_dir, 'all_feasible_states.pkl'), 'rb'))\n",
    "        out_feasible_starts = StateCollection(distance_threshold=distance_threshold)\n",
    "        print('number of feasible starts: ', old_all_feasible_starts.size)\n",
    "        cnt = 0\n",
    "        for start in old_all_feasible_starts.state_list:\n",
    "            obs = env.reset(init_state=start)\n",
    "#             print('Now start %i' %cnt)\n",
    "            cnt += 1\n",
    "            if cnt > 300:\n",
    "                break\n",
    "            if obs[16] > -0.5:\n",
    "                # print(\"got one more up to \", out_feasible_starts.size)\n",
    "                out_feasible_starts.append([start])\n",
    "        print(\"number of out feasible starts:\", out_feasible_starts.size)\n",
    "        while no_new_states < 5:\n",
    "            total_num_starts = out_feasible_starts.size\n",
    "            starts = out_feasible_starts.sample(100)\n",
    "            new_starts = generate_starts(env, starts=starts, horizon=1000, size=10, variance=brownian_variance,\n",
    "                                         animated=animate, speedup=10)\n",
    "            out_feasible_starts.append(new_starts)\n",
    "            num_new_starts = out_feasible_starts.size - total_num_starts\n",
    "            logger.log(\"number of new states: \" + str(num_new_starts))\n",
    "            if num_new_starts < 10:\n",
    "                no_new_states += 1\n",
    "#             with open(osp.join(log_dir, 'all_out_feasible_states.pkl'), 'wb') as f:\n",
    "#                 cloudpickle.dump(out_feasible_starts, f, protocol=3)\n",
    "    end_time = time.time()\n",
    "    print('Time needed for start state generation: %.2fmin' %((end_time - start_time)/60))\n",
    "    return out_feasible_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of feasible starts:  136039\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf425ee62cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_out_feasible_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_goal_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d8e5cfcbdb8d>\u001b[0m in \u001b[0;36mfind_out_feasible_states\u001b[0;34m(env, log_dir, distance_threshold, brownian_variance, animate)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mold_all_feasible_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#             print('Now start %i' %cnt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_start_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, init_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mGoalExplorationEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mGoalExplorationEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, reset_goal, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m#default behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_to_observation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_goal_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProxyEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the wrapped env needs to use or ignore it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProxyEnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Uni/Master/Semester3/DeepLearningLab/project/Code/rllab-curriculum-master/curriculum/envs/goal_env.py\u001b[0m in \u001b[0;36mappend_goal_observation\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_to_goal_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             )\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_goal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "new_starts = find_out_feasible_states(start_goal_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
