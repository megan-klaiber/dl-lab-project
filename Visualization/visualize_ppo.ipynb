{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************EDIT PATH***************\n",
    "# path to results directory\n",
    "results_dir = '../server_results/results/'\n",
    "\n",
    "sub_dir = os.listdir(results_dir)\n",
    "\n",
    "uniform = []\n",
    "good_starts = []\n",
    "all_previous = []\n",
    "\n",
    "# collect directory names of the sampling methods\n",
    "for dir in sub_dir:\n",
    "    #sampling_method = re.search('\\d_(.[^_]+?)_\\d', dir).group().split('_')[1]\n",
    "    if 'uniform' in dir:\n",
    "        uniform.append(dir)\n",
    "    elif 'good_starts' in dir:\n",
    "        good_starts.append(dir)\n",
    "    else:\n",
    "        all_previous.append(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_data = []\n",
    "\n",
    "# get all evaluation data\n",
    "for dir in uniform:\n",
    "    path = os.path.join(results_dir, dir)\n",
    "    #file = ([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))][0])\n",
    "    file = ([f for f in os.listdir(path) if 'evaluation_results' in f][0])\n",
    "    \n",
    "    with open(os.path.join(path, file)) as f:\n",
    "        uniform_data.append(json.load(f))\n",
    "\n",
    "        \n",
    "uniform_data_copy = []\n",
    "        \n",
    "# get average succes probability per iteration per file\n",
    "for data in uniform_data:\n",
    "    for it in data:\n",
    "        goals = data[it]\n",
    "        sums = np.sum(goals)\n",
    "        prob = sums / len(goals)\n",
    "        data[it] = prob\n",
    "    uniform_data_copy.append(data)\n",
    "\n",
    "# get one dictionary with all runs\n",
    "all_in_one_dict = {}\n",
    "for k in list(uniform_data_copy[0].keys())[:301]:\n",
    "    all_in_one_dict[k] = [d[k] for d in uniform_data_copy]  \n",
    "\n",
    "# get means and variances per iteration\n",
    "uniform_means = []\n",
    "uniform_variances = []\n",
    "\n",
    "for k in all_in_one_dict.keys():\n",
    "    mean = np.mean(all_in_one_dict[k])\n",
    "    uniform_means.append(mean)\n",
    "    var = np.std(all_in_one_dict[k])\n",
    "    uniform_variances.append(var)\n",
    "\n",
    "#print(uniform_data)\n",
    "#print(all_in_one_dict)\n",
    "#print(uniform_means)\n",
    "#print(uniform_variances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### good starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_starts_data = []\n",
    "\n",
    "\n",
    "# get all evaluation data\n",
    "for dir in good_starts:\n",
    "    path = os.path.join(results_dir, dir)\n",
    "    #file = ([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))][0])\n",
    "    file = ([f for f in os.listdir(path) if 'evaluation_results' in f][0])\n",
    "    \n",
    "    with open(os.path.join(path, file)) as f:\n",
    "        good_starts_data.append(json.load(f))      \n",
    "\n",
    "good_starts_data_copy = []\n",
    "        \n",
    "# get average succes probability per iteration per file\n",
    "for data in good_starts_data:\n",
    "    for it in data:\n",
    "        goals = data[it]\n",
    "        sums = np.sum(goals)\n",
    "        prob = sums / len(goals)\n",
    "        data[it] = prob\n",
    "    good_starts_data_copy.append(data)\n",
    "\n",
    "# get one dictionary with all runs\n",
    "all_in_one_dict = {}\n",
    "for k in list(good_starts_data_copy[0].keys())[:301]:\n",
    "    all_in_one_dict[k] = [d[k] for d in good_starts_data_copy]\n",
    "\n",
    "# get means and variances per iteration\n",
    "good_starts_means = []\n",
    "good_starts_variances = []\n",
    "\n",
    "for k in all_in_one_dict.keys():\n",
    "    mean = np.mean(all_in_one_dict[k])\n",
    "    good_starts_means.append(mean)\n",
    "    var = np.std(all_in_one_dict[k])\n",
    "    good_starts_variances.append(var)\n",
    "\n",
    "#print(good_starts_data)\n",
    "#print(all_in_one_dict)\n",
    "#print(good_starts_means)\n",
    "#print(good_starts_variances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### previous starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_previous_data = []\n",
    "\n",
    "# get all evaluation data\n",
    "for dir in all_previous:\n",
    "    path = os.path.join(results_dir, dir)\n",
    "    #file = ([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))][0])\n",
    "    file = ([f for f in os.listdir(path) if 'evaluation_results' in f][0])\n",
    "    \n",
    "    with open(os.path.join(path, file)) as f:\n",
    "        all_previous_data.append(json.load(f))\n",
    "\n",
    "        \n",
    "all_previous_data_copy = []\n",
    "        \n",
    "# get average succes probability per iteration per file\n",
    "for data in all_previous_data:\n",
    "    for it in data:\n",
    "        goals = data[it]\n",
    "        sums = np.sum(goals)\n",
    "        prob = sums / len(goals)\n",
    "        data[it] = prob\n",
    "    all_previous_data_copy.append(data)\n",
    "\n",
    "# get one dictionary with all runs\n",
    "all_in_one_dict = {}\n",
    "for k in list(all_previous_data_copy[0].keys())[:301]:\n",
    "    all_in_one_dict[k] = [d[k] for d in all_previous_data_copy]\n",
    "\n",
    "# get means and variances per iteration\n",
    "all_previous_means = []\n",
    "all_previous_variances = []\n",
    "\n",
    "for k in all_in_one_dict.keys():\n",
    "    mean = np.mean(all_in_one_dict[k])\n",
    "    all_previous_means.append(mean)\n",
    "    var = np.std(all_in_one_dict[k])\n",
    "    all_previous_variances.append(var)\n",
    "\n",
    "#print(all_previous_data)\n",
    "#print(all_in_one_dict)\n",
    "#print(all_previous_means)\n",
    "#print(all_previous_variances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = range(len(all_in_one_dict.keys()))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "#uniform\n",
    "ax.plot(iterations, uniform_means, label = 'Uniform Sampling (baseline)', color='#d83233')\n",
    "ax.fill_between(iterations, np.array(uniform_means)+np.array(uniform_variances), np.array(uniform_means)-np.array(uniform_variances), facecolor='#d83233', alpha=0.5)\n",
    "# good_starts\n",
    "ax.plot(iterations, good_starts_means, label = 'Brownian from Good Starts', color='green')\n",
    "ax.fill_between(iterations, np.array(good_starts_means)+np.array(good_starts_variances), np.array(good_starts_means)-np.array(good_starts_variances), facecolor='green', alpha=0.5)\n",
    "# all_previous\n",
    "ax.plot(iterations, all_previous_means, label = 'Brownian from All Starts', color='royalblue')\n",
    "ax.fill_between(iterations, np.array(all_previous_means)+np.array(all_previous_variances), np.array(all_previous_means)-np.array(all_previous_variances), facecolor='royalblue', alpha=0.5)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Learning Iterations\")\n",
    "plt.ylabel(\"Average success probability on $s_0$ ~ $\\\\rho_0$\")\n",
    "plt.ylim(0,1,0.2)\n",
    "plt.xlim(0,len(all_in_one_dict.keys()),1)\n",
    "\n",
    "plt.legend()\n",
    "#plt.title(\"learning curve of maze runs with PPO\")\n",
    "\n",
    "if not os.path.exists(\"../poster/images/\"):\n",
    "    os.mkdir(\"../poster/images/\")\n",
    "\n",
    "plt.savefig('../poster/images/maze_ppo_learning_curve.svg')\n",
    "plt.savefig('../poster/images/maze_ppo_learning_curve.png')\n",
    "plt.savefig('../poster/images/maze_ppo_learning_curve.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
